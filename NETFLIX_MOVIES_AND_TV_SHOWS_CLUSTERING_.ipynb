{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivam887423/Netflix-movie-and-TV-show-Clustering/blob/main/NETFLIX_MOVIES_AND_TV_SHOWS_CLUSTERING_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Netflix Movies and TV show clustering\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1** -**Sandeep Salunke**\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The entertainment industry is highly competitive, and success is dependent on various factors, including genre, rating, production budget, cast, and more. In this context, a study was conducted to understand the factors influencing the popularity of movies and TV shows on Netflix. The study used a dataset containing around 12 variables to cluster the movies and TV shows based on their popularity and audience preferences.\n",
        "The first step in the analysis involved data wrangling, where missing values were handled, and unique values were checked. The study identified that there were 2389 missing values for the 'director' column, 718 for the 'cast' column, 507 for the 'country' column, and 10 for the 'date_added' column. These missing values were removed by dropping the corresponding rows.\n",
        "\n",
        "Next, the study performed exploratory data analysis (EDA). The number of movies on Netflix is greater than the number of TV shows, with 5372 movies and 2398 TV shows currently available on the platform. The most common rating for TV shows is TV-MA, indicating that a significant portion of the TV shows available on Netflix are intended for adult audiences. Additionally, TV-MA is the most common rating for both movies and TV shows, suggesting that Netflix's content caters to a primarily adult demographic, with a focus on mature and potentially controversial themes.\n",
        "The years 2017 and 2018 had the highest number of movie releases, while 2020 had the highest number of TV show releases. The growth rate of movie releases on Netflix is significantly faster than that of TV shows. Since 2015, there has been a substantial increase in the number of movies and TV show episodes available on Netflix. However, there has been a notable drop in the number of movies and TV show episodes produced after 2020. It appears that Netflix has given more attention to increasing its movie content rather than TV shows.\n",
        "\n",
        "According to the countplot, it appears that Netflix adds the highest number of movies and TV shows during the period between October and January. This period seems to be the busiest time of year for Netflix in terms of adding new content to its platform. Netflix has the highest number of content in the United States, followed by India. India has the highest number of movies on Netflix.\n",
        "\n",
        "To cluster the shows, the study focused on six key attributes: director, cast, country, genre, rating, and description. These attributes were transformed into a 10,000-feature TFIDF vectorization, and Principal Component Analysis (PCA) was used to reduce the components to 3000, capturing more than 80% of the variance.\n",
        "Next, two clustering algorithms, K-Means and Agglomerative clustering, were used to group the shows. K-Means determined that the optimal number of clusters was 5, while Agglomerative clustering suggested 7 clusters, which were visualized using a dendrogram.\n",
        "\n",
        "Finally, a content-based recommender system was created using the similarity matrix obtained through cosine similarity. This system provides personalized recommendations based on the type of show the user has watched, giving them 10 top-notch suggestions to explore.\n",
        "In summary, the study identified key trends in the Netflix dataset, including the growth rate of movies versus TV shows, the busiest period for adding new content, and the content demographics. Through clustering and a content-based recommender system, the study was able to provide personalized recommendations based on the user's viewing history. This study provides valuable insights into the factors influencing the popularity of movies and TV shows on Netflix, offering a foundation for further research and analysis.."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Sandeep81299/Netflix-Movies-and-TV-shows-Prediction"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine.**\n",
        "\n",
        "**In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming service’s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset.**\n",
        "\n",
        "**Integrating this dataset with other external datasets such as IMDB ratings, rotten tomatoes can also provide many interesting findings**\n",
        "\n",
        "**In this project, you are required to do**\n",
        "\n",
        "1.Exploratory Data Analysis.\n",
        "\n",
        "2.Understanding what type content is available in different countries.\n",
        "\n",
        "3.Is Netflix has increasingly focusing on TV rather than movies in recent years.\n",
        "\n",
        "4.Clustering similar content by matching text-based features."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "import missingno as msno\n",
        "%matplotlib inline\n",
        "\n",
        "# Word Cloud library\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "# library used for textual data prerocessing\n",
        "import string\n",
        "string.punctuation\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from scipy.stats import ttest_ind\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# library used for Clusters impelementation\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import scipy.cluster.hierarchy as shc\n",
        "\n",
        "# library used for building recommandation system\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Warnings library. Would help to throw away warnings caused.\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading CSV File\n",
        "df = pd.read_csv('/content/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')"
      ],
      "metadata": {
        "id": "dMYWGNM4PjKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(f\"The total number of duplicated observations in the dataset: {df.duplicated().sum()}\")\n"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "missing_values = df.isnull().sum().sort_values(ascending=False)\n",
        "missing_values\n"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# Create a bar chart of missing values\n",
        "plt.bar(missing_values.index, missing_values.values)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Missing Values Bar Chart')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Netflix Movies and TV Shows Clustering Dataset contains 12 columns, with only one having an integer data type. The dataset does not have any duplicates, but it does have null values in five columns: director, cast, country, date_added, and rating.\n",
        "\n",
        "This dataset is valuable for investigating patterns in the types of movies and TV shows that are available on Netflix. It can also be used to develop clustering models that group similar titles together based on shared attributes, such as genre, country of origin, and rating."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "print(f\"Columns name:\\n{df.columns.to_list()}\")\n",
        "     "
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe(include=\"all\")"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**show_id** : Unique ID for every Movie / Tv Show\n",
        "\n",
        "**type** : Identifier - A Movie or TV Show\n",
        "\n",
        "**title** : Title of the Movie / Tv Show\n",
        "\n",
        "**director** : Director of the Movie\n",
        "\n",
        "**cast** : Actors involved in the movie / show\n",
        "\n",
        "**country** : Country where the movie / show was produced\n",
        "\n",
        "**date_added** : Date it was added on Netflix\n",
        "\n",
        "**release_year** : Actual Releaseyear of the movie / show\n",
        "\n",
        "**rating** : TV Rating of the movie / show\n",
        "\n",
        "**duration** : Total Duration - in minutes or number of seasons\n",
        "\n",
        "**listed_in** : Genere\n",
        "\n",
        "**description**: The Summary description"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1.  Handling Null values from each feature"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "missing_values = df.isnull().sum().sort_values(ascending=False)\n",
        "print(missing_values)\n",
        "#percentage of null values \n",
        "print(\"missing_values by percentage\")\n",
        "missing_values= df.isnull().sum().sort_values(ascending=False)/len(df)\n",
        "print(f\"{missing_values*100}%\")"
      ],
      "metadata": {
        "id": "wikHR9AFvqja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Since 'date_added' and 'rating' has very less percentage of null count so we can drop those observations to avoid any biasness in our clustering model.\n",
        "2. We cannot drop or impute any values in 'director' and 'cast' as the null percentage is comparatevely high and we do not know data of those actual movie/TV shows, so its better to replace those entries with 'unknown' and No cast.\n",
        "3. We can fill null values of 'country' with mode as we only have 6% null values and most of the movies/shows are from US only."
      ],
      "metadata": {
        "id": "W_qvzyfNv3MI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#'date_added' and 'rating' contains an insignificant portion of the data so we will drop them from the dataset\n",
        "df.dropna(subset=['date_added','rating'],inplace=True)"
      ],
      "metadata": {
        "id": "5q2U7fXAMbBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# imputing with unknown in null values of director \n",
        "df['director'].fillna(\"Unknown\",inplace=True)\n",
        "\n",
        "# imputing with unknown in null values of cast feature\n",
        "df['cast'].fillna(value='No cast',inplace=True)\n",
        "\n",
        "# Imputing null values of country with Mode\n",
        "df['country'].fillna(value=df['country'].mode()[0],inplace=True)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#again checking is there any null values are not\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "PeqHqMV2Mkdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Typecasting of attributes"
      ],
      "metadata": {
        "id": "yvPfsPYy3CrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking info of the dataset before typecasting\n",
        "df.info()"
      ],
      "metadata": {
        "id": "atAnIgYx3EV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Binning of Rating attribute"
      ],
      "metadata": {
        "id": "fSb0B2531TPO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In rating columns we have different categories these are content rating classifications that are commonly used in the United States and other countries to indicate the appropriateness of media content for different age groups. Let's understand each of them and binnig them accordingly:\n",
        "\n",
        "**TV-MA**: This rating is used for mature audiences only, and it may contain strong language, violence, nudity, and sexual content.\n",
        "\n",
        "**R**: This rating is used for movies that are intended for audiences 17 and older. It may contain graphic violence, strong language, drug use, and sexual content.\n",
        "\n",
        "**PG-13**: This rating is used for movies that may not be suitable for children under 13. It may contain violence, mild to moderate language, and suggestive content.\n",
        "\n",
        "**TV-14**: This rating is used for TV shows that may not be suitable for children under 14. It may contain violence, strong language, sexual situations, and suggestive dialogue.\n",
        "\n",
        "**TV-PG**: This rating is used for TV shows that may not be suitable for children under 8. It may contain mild violence, language, and suggestive content.\n",
        "\n",
        "**NR**: This stands for \"Not Rated.\" It means that the content has not been rated by a rating board, and it may contain material that is not suitable for all audiences.\n",
        "\n",
        "**TV-G**: This rating is used for TV shows that are suitable for all ages. It may contain some mild violence, language, and suggestive content.\n",
        "\n",
        "**TV-Y**: This rating is used for children's TV shows that are suitable for all ages. It is intended to be appropriate for preschool children.\n",
        "\n",
        "**TV-Y7**: This rating is used for children's TV shows that may not be suitable for children under 7. It may contain mild violence and scary content.\n",
        "\n",
        "**PG**: This rating is used for movies that may not be suitable for children under 10. It may contain mild language, some violence, and some suggestive content.\n",
        "\n",
        "**G**: This rating is used for movies that are suitable for general audiences. It may contain some mild language and some violence.\n",
        "\n",
        "**NC-17**: This rating is used for movies that are intended for adults only. It may contain explicit sexual content, violence, and language.\n",
        "\n",
        "**TV-Y7-FV**: This rating is used for children's TV shows that may not be suitable for children under 7. It may contain fantasy violence.\n",
        "\n",
        "**UR**: This stands for \"Unrated.\" It means that the content has not been rated by a rating board, and it may contain material that is not suitable for all audiences.\n",
        "\n",
        "Let's not complicate it and create bins as following:\n",
        "* **Adult Content**: TV-MA, NC-17, R\n",
        "* **Children Content**:  TV-PG, PG, TV-G, G\n",
        "* **Teen Content**: PG-13, TV-14\n",
        "* **Family-friendly Content**: TV-Y, TV-Y7, TV-Y7-FV\n",
        "* **Not Rated**: NR, UR"
      ],
      "metadata": {
        "id": "zvEgjuTv1WyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['rating']"
      ],
      "metadata": {
        "id": "4H9h5Met18t3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binning the values in the rating column\n",
        "rating_map = {'TV-MA':'Adult Content',\n",
        "              'R':'Adult Content',\n",
        "              'PG-13':'Teen Content',\n",
        "              'TV-14':'Teen Content',\n",
        "              'TV-PG':'Children Content',\n",
        "              'NR':'Not Rated',\n",
        "              'TV-G':'Children Content',\n",
        "              'TV-Y':'Family-friendly Content',\n",
        "              'TV-Y7':'Family-friendly Content',\n",
        "              'PG':'Children Content',\n",
        "              'G':'Children Content',\n",
        "              'NC-17':'Adult Content',\n",
        "              'TV-Y7-FV':'Family-friendly Content',\n",
        "              'UR':'Not Rated'}\n",
        "\n",
        "df['rating'].replace(rating_map, inplace = True)\n",
        "df['rating'].unique()"
      ],
      "metadata": {
        "id": "fS8vR41y2YJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert 'type' column to categorical data type\n",
        "df['type'] = pd.Categorical(df['type'])\n",
        "\n",
        "# create a new categorical column 'target_ages' with specified categories\n",
        "df['rating'] = pd.Categorical(df['rating'])"
      ],
      "metadata": {
        "id": "EMimhxGx5hN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets check the dataset now\n",
        "df.head()"
      ],
      "metadata": {
        "id": "zo1lpd4O2r67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Separating Movies and TV Shows"
      ],
      "metadata": {
        "id": "fygGFtKS5-Fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating two extra columns\n",
        "tv_shows=df[df['type']=='TV Show']\n",
        "movies=df[df['type']=='Movie']"
      ],
      "metadata": {
        "id": "-_S6O5G92fTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####5. Extracting some columns \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pRX4GNrd_jNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting date, day, month and year from date_added column\n",
        "df['month'] = pd.DatetimeIndex(df['date_added']).month\n",
        "df['year'] = pd.DatetimeIndex(df['date_added']).year\n",
        "df['day'] = pd.DatetimeIndex(df['date_added']).day\n"
      ],
      "metadata": {
        "id": "SsrZFKsw_tDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have divided data wrangling into five different sections:\n",
        "1. In this section we have imputed/drop the null values of:\n",
        "  * Imputed 'director' and 'cast' with 'Unknown' and 'No Cast'.\n",
        "  * Imputed 'country' with Mode.\n",
        "  * Drop null values of 'date_added' and 'rating' (less percentage).\n",
        "\n",
        "2.* We have typecasted the following features:\n",
        "    * 'duration' into integer (Removing min and seasons from the values).\n",
        "    * 'date_added' to datetime (Into the required format).\n",
        "\n",
        "3. We have seen that the 'rating' column contains various coded categories, so  we have decided to create 5 bins and distribute the values accordingly:\n",
        "    * **Adult**: TV-MA, NC-17\n",
        "    * **Restricted**: R, UR\n",
        "    * **Teen**: PG-13, TV-14\n",
        "    * **All Ages**: TV-G, TV-Y, TV-Y7, TV-Y7-FV, PG, G, TV-PG\n",
        "    * **Not Rated**: NR    \n",
        "\n",
        "4. Lastly we have splitted the dataframe into two df one is 'df_movies' that contains only Movies and the other is 'df_tvshows' that contains only TV Shows for our further analysis."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - **1.Type**"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(What is the relative percentage of total number of Movies and TV Shows over Netflix?)"
      ],
      "metadata": {
        "id": "E2cPzZTsx7a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "sns.set_style('darkgrid')\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='type', data=df, palette='pastel')\n",
        "#labeling of values\n",
        "plt.title('Number of Movies and TV Shows', fontsize=14)\n",
        "plt.xlabel('Type', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "#Visualization of number of movies and tv shows\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "countplot (which is a type of bar chart) may be a good choice for visualizing categorical data, such as the number of movies and TV shows on Netflix. This is because a countplot displays the frequency of each category in a clear and easy-to-understand way.."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. We can see that the majority of the content on Netflix is movies, which account for around two-thirds of the total content. TV shows make up the remaining one-third of the content.\n",
        "\n",
        "2. we can conclude that in the given Data set only **28.3% are TV Shows and 71.7% are Movies.**"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insight that there are more movies on Netflix than TV shows is unlikely to have a significant positive or negative business impact on its own. However, this information could be used in conjunction with other insights and data to inform business decisions.\n",
        "\n",
        "For example, if Netflix notices that TV shows are more popular with its subscribers than movies, it may decide to focus more on acquiring TV show content. Alternatively, if it sees that its original movie productions are gaining popularity, it may decide to invest more in that area.\n",
        "\n",
        "In terms of negative growth, the specific insight that there are more movies than TV shows on Netflix is unlikely to have a negative impact on its own. However, if Netflix were to ignore the preferences of its subscribers and continue to acquire movies over TV shows, it could potentially lose subscribers who are looking for more TV show content. Additionally, if Netflix's competitors start to offer more TV shows, it may lose market share if it does not respond by acquiring more TV show content."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - **2.Rating**"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  (How content is distributed over Netflix?)"
      ],
      "metadata": {
        "id": "xQDjovLkyY0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25,10))\n",
        "for i,j,k in ((df, 'Overall',0),(movies, 'Movies',1),(tv_shows, 'TV Shows',2)):\n",
        "  plt.subplot(1,3,k+1)\n",
        "  count= i['rating'].value_counts()\n",
        "  plt.pie(count, labels=count.index,explode=(0,0,0,0,0.5),colors=['orangered','dodgerblue','lightgreen','mediumslateblue','yellow'],\n",
        "          autopct='%1.1f%%', labeldistance=1.1,wedgeprops={\"edgecolor\" : \"black\",'linewidth': 1,'antialiased': True})\n",
        "  plt.title(f\"Distribution of Content Rating on Netflix '{j}'\")\n",
        "  plt.axis('equal')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PAbuc6l8T9qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose this chart because it effectively shows the distribution of TV show ratings in a clear and concise manner. The pie chart allow for easy comparison between the different ratings, and the ordering by count from highest to lowest further emphasizes the dominance of TV-MA. Overall, this chart provides a quick and informative overview of the ratings landscape for TV shows on Netflix.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the dataset, TV-MA is the most common rating for TV shows, with the highest number of occurrences in the 'rating' column. This indicates that a significant portion of the TV shows available on Netflix are intended for adult audiences.According to the dataset, TV-MA is the most common rating for both movies and TV shows. This indicates that a significant portion of the content available on Netflix is intended for adult audiences. Specifically, TV-MA has the highest number of occurrences in the 'rating' column for TV shows, while for movies it is also the most common rating. This suggests that Netflix's content caters to a primarily adult demographic, with a focus on mature and potentially controversial themes."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights can have a positive impact on Netflix's business strategy. Knowing that TV-MA is the most common rating for both movies and TV shows, Netflix can continue to focus on producing and acquiring content that appeals to adult audiences. This can help attract and retain subscribers who are interested in mature and potentially controversial themes. Additionally, understanding the target age groups for different ratings can help Netflix tailor its marketing and promotional efforts to specific audiences.\n",
        "\n",
        "However, there is a potential negative impact as well. Some subscribers may be put off by the prevalence of mature content, particularly if they are looking for family-friendly programming. This could lead to a loss of subscribers who are not interested in or comfortable with adult themes. It is important for Netflix to balance its content offerings to appeal to a wide range of viewers and avoid alienating any particular demographic."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - **3.Release Year**"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a line chart to visualize the number of movies and TV shows released each year\n",
        "#Extracting the count of movies and TV shows for each year\n",
        "movies_year = movies['release_year'].value_counts().sort_index(ascending=False)\n",
        "tvshows_year = tv_shows['release_year'].value_counts().sort_index(ascending=False)\n",
        "\n",
        "#Creating a line plot using Seaborn\n",
        "sns.set(style='whitegrid', font_scale=1.2)\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "ax = sns.lineplot(x=movies_year.index, y=movies_year.values, color='maroon', label='Movies', linewidth=2.5, marker='o')\n",
        "ax = sns.lineplot(x=tvshows_year.index, y=tvshows_year.values, color='blue', label='TV Shows', linewidth=2.5, marker='o')\n",
        "\n",
        "#Customizing the plot\n",
        "plt.xticks(rotation=90)\n",
        "ax.set_xlabel('Release Year', fontsize=14)\n",
        "ax.set_ylabel('Number of Titles', fontsize=14)\n",
        "ax.set_title('Production Growth Yearly', fontsize=18, pad=15)\n",
        "plt.legend(fontsize=14)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the last 20 years from the dataset\n",
        "last_20_years = range(2001, 2020)\n",
        "\n",
        "# Filter the dataset to only include movies from the last 20 years\n",
        "movies_last_20_years = movies[movies['release_year'].isin(last_20_years)]\n",
        "\n",
        "# Create a count plot of the number of movies released per year\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.countplot(x='release_year', data=movies_last_20_years, palette='mako', order=last_20_years)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.xlabel('Year of Release')\n",
        "plt.ylabel('Number of Movies Released')\n",
        "plt.title('Number of Movies Released per Year in the Last 20 Years')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dtBIOp1Icati"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best chart to use would be a line chart or a bar chart to display the number of movies and TV shows released per year from 2015 to 2020. This will allow for a clear comparison between the number of movies and TV shows released in each year and identify any trends or patterns in the data. Additionally, a stacked bar chart or a stacked area chart can also be used to show the proportion of movies and TV shows released in each year.\n",
        "\n",
        "As for why I chose this specific chart, I believe it is because it effectively conveys the message that the number of movies released on Netflix is growing faster than the number of TV shows. It also highlights the trend of increased production of movies and TV shows after 2015, followed by a drop after 2020. Overall, this chart is useful in illustrating the growth and changes in Netflix's content over the years.."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The years 2017 and 2018 had the highest number of movie releases, while 2020 had the highest number of TV show releases.\n",
        "\n",
        "The growth rate of movie releases on Netflix is significantly faster than that of TV shows.\n",
        "\n",
        "Since 2015, there has been a substantial increase in the number of movies and TV show episodes available on Netflix.\n",
        "\n",
        "However, there has been a notable drop in the number of movies and TV show episodes produced after 2020.\n",
        "\n",
        "It appears that Netflix has given more attention to increasing its movie content rather than TV shows, as the growth rate of movies has been much more significant than that of TV shows."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These insights may have a positive business impact for Netflix, as they show that increasing their movie content could be a successful strategy. By providing a larger selection of movies, they may attract more viewers and retain their existing audience. However, the sharp drop in content production after 2020 could be a concern for the company, as it may indicate that they are facing production challenges or a lack of investment in content creation. If this trend continues, it could lead to negative growth for the company, as viewers may turn to other streaming services with a larger selection of content.\n",
        "\n",
        "In conclusion, while the insights gained from the analysis suggest potential opportunities for Netflix, it is important to continue monitoring trends and adapting to changes in the market to ensure continued growth and success."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - **4.Release_month**"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Countplot of Month by Type\n",
        "fig, ax = plt.subplots(figsize=(15, 6))\n",
        "\n",
        "sns.countplot(x='month', hue='type', data=df, palette='Set1', ax=ax, edgecolor='black', linewidth=2.5)\n",
        "ax.set_title('Countplot of Month by Type', fontsize=16)\n",
        "ax.set_xlabel('Month', fontsize=14)\n",
        "ax.set_ylabel('Count', fontsize=14)\n",
        "ax.legend(fontsize=12, title='Type', title_fontsize=12)\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cWsR5SmCiutg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked the specific chart, which is a countplot with hue, because it allows us to easily visualize and compare the number of movies and TV shows added to Netflix each month. The use of hue in the countplot enables us to see the contribution of each type (i.e. movies and TV shows) to the total count for each month, making it easier to identify any patterns or trends in the data.\n",
        "\n",
        "In this case, we can clearly see that from October to January, there was a peak in the number of movies and TV shows added to Netflix. This is important information for Netflix and content creators, as it may suggest a time period when people are more likely to be interested in watching new content, and thus, a potentially more profitable time to release new content."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the countplot, it appears that Netflix adds the highest number of movies and TV shows during the period between October and January. This period seems to be the busiest time of year for Netflix in terms of adding new content to its platform."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insight that the most content is added to Netflix from October to January can potentially help create a positive business impact. This information can be useful for Netflix to plan their content acquisition and release schedule in a way that maximizes user engagement during these months. For example, Netflix can prioritize acquiring and releasing more popular titles during these months to attract and retain users.\n",
        "\n",
        "However, it's important to note that the information from the countplot alone may not be sufficient to create a significant positive impact. Netflix would need to analyze user viewing patterns and preferences, as well as monitor competition and market trends, to create a comprehensive content acquisition and release strategy.\n",
        "\n",
        "Regarding negative growth, the countplot alone does not provide any insights that would lead to negative growth. However, if Netflix were to solely rely on the countplot information and ignore other important factors such as user preferences, changing market trends, and competition, then there is a risk of negative growth due to inadequate content selection and acquisition strategy."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 Who are the top genre in Movies and TV Shows?"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Top 10 genres of movies\n",
        "top10_movies = movies['listed_in'].value_counts().index[0:10]\n",
        "\n",
        "#Top 10 Genres of Tv shows\n",
        "top10_tvshows = tv_shows['listed_in'].value_counts().index[0:10]\n",
        "\n",
        "#Visualization\n",
        "plt.style.use('default')\n",
        "plt.figure(figsize=(23,8))\n",
        "\n",
        "#Plot 1 - Top 10 Genres of Movies\n",
        "plt.subplot(1,2,1)\n",
        "sns.countplot(y='listed_in', data=movies, order=top10_movies, palette='muted')\n",
        "plt.title('Top 10 Genres of Movies', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Count', fontsize=14)\n",
        "plt.ylabel('Genre', fontsize=14)\n",
        "sns.despine()\n",
        "plt.tight_layout()\n",
        "\n",
        "#Plot 2 - Top 10 Genres of TV Shows\n",
        "plt.subplot(1,2,2)\n",
        "sns.countplot(y='listed_in', data=tv_shows, order=top10_tvshows, palette='pastel')\n",
        "plt.title('Top 10 Genres of TV Shows', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Count', fontsize=14)\n",
        "plt.ylabel('Genre', fontsize=14)\n",
        "sns.despine()\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the count of netflix shows and tv shows."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix offers a diverse range of TV show genres, each with its own unique flavor and appeal. However, one genre that stands out as a perennial favorite among viewers of all ages is kids TV.\n",
        "\n",
        "With an impressive selection of animated and live-action shows, Netflix's kids TV category is the perfect destination for families looking for high-quality, entertaining content that is both fun and educational. From beloved classics like SpongeBob SquarePants and Power Rangers to exciting new series like Carmen Sandiego and The Dragon Prince, Netflix's kids TV library has something for every young viewer.\n",
        "\n",
        "Moreover, Netflix's kids TV category is designed with parents in mind, offering a safe and secure viewing environment that allows them to have peace of mind while their kids enjoy their favorite shows. The parental controls feature allows parents to set age-appropriate content filters, monitor viewing history, and restrict access to certain shows or movies.\n",
        "\n",
        "So, whether you're looking for a way to keep your little ones entertained on a rainy day, or just want to bond with your family over a great TV show, Netflix's kids TV category is the perfect place to start. With its vast selection of entertaining and educational content, it's no wonder that kids TV remains one of the top genres on the platform."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top genre for TV shows on Netflix is kids TV, which includes a range of educational and entertaining content for children of all ages. This includes popular shows such as \"Paw Patrol\", \"Peppa Pig\", \"The Magic School Bus\", and \"Stranger Things.\"\n",
        "\n",
        "The insights gained from this information could definitely have a positive business impact. By knowing which genres are most popular, Netflix can tailor their content offerings and marketing strategies to appeal to their target audience. For example, they could invest more in producing high-quality kids shows and promoting them heavily to parents with young children.\n",
        "\n",
        "However, there could also be some negative growth associated with this trend. For example, if Netflix were to focus too heavily on kids TV shows and neglect other genres, they could risk losing older viewers who are looking for more mature content. Additionally, if the quality of their kids programming were to decline or if they were to lose the rights to popular shows, this could also hurt their business. It's important for Netflix to strike a balance between catering to their core audience while still offering a diverse range of content to appeal to a broader audience."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6.What is the Distribution of Duration of contents over Netflix?"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of Movie Durations\n",
        "# Create a figure and set its size\n",
        "plt.figure(figsize=(25, 10))\n",
        "\n",
        "# Extract the duration values as integers using regex and plot a histogram\n",
        "#sns.distplot(movies['duration'].str.extract('(\\d+)').astype(int), kde=False, color='green')\n",
        "plots= sns.distplot(movies['duration'].str.extract('(\\d+)').astype(int),kde=False, color=['green'])\n",
        "plt.grid(linestyle='--', linewidth=0.3)\n",
        "plt.title('Distplot with Normal distribution for Movies',fontweight=\"bold\")\n",
        "for bar in plots.patches:\n",
        "   plots.annotate(bar.get_height(),\n",
        "                  (bar.get_x() + bar.get_width() / 2,\n",
        "                   bar.get_height()), ha='center', va='bottom',\n",
        "                  size=10, xytext=(0, 5),\n",
        "                  textcoords='offset points',fontweight='bold',rotation=90)\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the figure size\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# Create a count plot of TV show durations\n",
        "sns.countplot(x=tv_shows['duration'], data=tv_shows, order=tv_shows['duration'].value_counts().index)\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title(\"Distribution of TV Show Durations\", fontweight='bold')\n",
        "\n",
        "# Set the x-axis label\n",
        "plt.xlabel(\"Duration (seasons)\")\n",
        "\n",
        "# Set the y-axis label\n",
        "plt.ylabel(\"Count\")\n",
        "\n",
        "# Rotate the x-axis labels\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CzHdhfHdnzeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Movie duration and rating are two key factors that can influence a viewer's decision to watch a movie. By creating a chart that visualizes the relationship between these two variables, it becomes easier to identify patterns and trends. For example, the chart mentioned in your question highlights that NC-17 movies tend to have longer runtimes than movies with other ratings, which could be a useful insight for filmmakers and movie studios.\n",
        "\n",
        "Similarly, the chart also shows that TV-Y rated movies tend to have shorter runtimes, which could be useful for parents looking for age-appropriate content for their children. Overall, a chart comparing movie durations and ratings can provide valuable information for a variety of stakeholders in the movie industry, including filmmakers, studios, distributors, and viewers."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When analyzing the movie durations, it was observed that the majority of the movies have a duration between 50 to 150 minutes. On the other hand, the TV shows have a large number of single-season shows, which indicates that most of the TV shows on Netflix are relatively new.\n",
        "\n",
        "Furthermore, the analysis showed that movies with a rating of NC-17 have the longest average duration. This might be because the movies with such a rating can explore more mature themes and include more explicit content, which requires a longer runtime to tell a compelling story.\n",
        "\n",
        "In contrast, the analysis also revealed that movies with a TV-Y rating, which is suitable for all children, have the shortest runtime on average. This suggests that the movies with this rating tend to be shorter and may have simpler plots and themes that are suitable for younger audiences."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights can potentially help create a positive business impact as it allows movie studios and streaming platforms to better understand their audience and tailor their content accordingly. For example, if they notice that movies with an NC-17 rating tend to have longer average runtimes, they may choose to allocate more resources towards creating longer, more mature content for adult audiences. Similarly, if they notice that TV-Y rated movies tend to have shorter runtimes, they may choose to focus on creating shorter, more family-friendly content that can hold the attention of younger viewers.\n",
        "\n",
        "However, there could also be insights that lead to negative growth. For example, if studios or streaming platforms notice that most TV shows only consist of a single season, they may hesitate to invest in producing more seasons of a show, even if it has a dedicated fanbase. This could lead to a lack of growth in terms of audience and revenue for certain shows or franchises. Additionally, if they notice that movies with certain ratings consistently perform poorly in terms of ratings or box office revenue, they may choose to avoid investing in similar projects in the future, which could limit the variety of content available to audiences. Ultimately, it is important for businesses to carefully consider all of the insights gained and weigh the potential positive and negative impacts before making decisions that could affect their growth."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7.What are the top 10 Countries involved in content creation?"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "df_country = df.groupby(['country']).agg({'title':'nunique'}).reset_index().sort_values(by=['title'],ascending=False)[:10]\n",
        "plt.figure(figsize=(15,6))\n",
        "plots= sns.barplot(y = \"country\",x = 'title', data = df_country)\n",
        "plt.xticks(rotation = 60)\n",
        "plt.title('Top 10 Countries for content creation')\n",
        "plt.grid(linestyle='--', linewidth=0.3)\n",
        "plots.bar_label(plots.containers[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#top_two countries where netflix is most popular\n",
        "country=df['country'].value_counts().reset_index()\n",
        "country"
      ],
      "metadata": {
        "id": "0GuXrb_3r1Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the given information, we can say that the United States has the highest number of content on Netflix, followed by India. Additionally, India has the highest number of movies on Netflix.\n",
        "\n",
        "To communicate this information visually, a bar chart or a horizontal bar chart would be a good choice. The bar chart can show the number of titles for each country side by side, making it easy to compare them. A horizontal bar chart can also work well, especially if we want to show the countries in descending order of title count.."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix has the highest number of content in the United States, followed by India. India has the highest number of movies on Netflix."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to our analysis, the United States has the highest number of content on Netflix, followed by India. Interestingly, India has the highest number of movies on Netflix.\n",
        "\n",
        "These insights can be useful for Netflix in a number of ways. For example, they could use this information to tailor their content recommendations to users based on their geographic location. They could also use this information to determine which types of content to focus on producing in the future.\n",
        "\n",
        "However, there are also some potential negative impacts to consider. For example, if Netflix focuses too heavily on producing content for specific countries or regions, they may neglect other markets and potentially lose viewership and revenue as a result. Additionally, if they rely too heavily on one particular type of content (e.g. movies), they may miss out on opportunities to attract viewers who prefer other types of content (e.g. TV shows or documentaries).\n",
        "\n",
        "Overall, while the insights gained from our analysis can certainly be useful for informing business decisions at Netflix, it's important to approach these insights with a balanced and nuanced perspective, taking into account potential positive and negative impacts."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8.What is the Rate of Movies/TV Shows adding per day, month and year on Netflix?"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "interval= ['year','month','day']\n",
        "plt.figure(figsize=(20,5))\n",
        "for i,j in enumerate(interval):\n",
        "  plt.subplot(1,3,i+1)\n",
        "  df_interval = df.groupby([j,'type']).agg({'title':'nunique'}).reset_index().sort_values(by=[j],ascending=False)\n",
        "  sns.lineplot(x = j,y='title', data = df_interval, palette = 'husl', hue = df_interval['type'], marker = 'o')\n",
        "  plt.title(f\"Content added per {j}\")\n",
        "  plt.ylabel(f\"Content count\")\n",
        "  plt.grid(linestyle='--', linewidth=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the content added."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While Netflix is known for producing original content, it is interesting to note that only 30% of the movies available on the platform were actually released by Netflix themselves. The remaining 70% of movies were added to Netflix after being released by different modes, such as theaters or other streaming platforms.\n",
        "\n",
        "This fact highlights the vast library of movies that Netflix has acquired over the years, providing viewers with a diverse range of content from all around the world. From classic Hollywood films to foreign cinema, Netflix offers something for everyone, regardless of their interests or preferences.\n",
        "\n",
        "So, the next time you're scrolling through Netflix's extensive movie catalog, remember that only a small fraction of what you see is actually original content. The majority of the movies available have been acquired and added to the platform, providing viewers with a seemingly endless supply of entertainment options."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the positive side, the fact that 70% of movies added on Netflix were released earlier by a different mode suggests that Netflix is able to acquire popular content that has already been released elsewhere. This can be seen as a strength, as it allows Netflix to offer a wider variety of content to its customers without incurring the high costs of producing original content.\n",
        "\n",
        "Furthermore, the fact that 30% of movies released on Netflix suggests that Netflix is investing in creating its own original content. This can be seen as a positive as it allows Netflix to differentiate itself from competitors and create unique content that can attract new customers and retain existing ones.\n",
        "\n",
        "However, on the negative side, if Netflix is not able to produce original content that is as popular as the acquired content, it could lead to a decline in subscribers. Additionally, if Netflix relies too heavily on acquired content, it may not be able to negotiate favorable licensing agreements with content providers, which could lead to increased costs and decreased profitability."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9 Total number of Movies/TV Shows added per month on Netflix?"
      ],
      "metadata": {
        "id": "Yh7IjWZyNyat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(23,8))\n",
        "for i,j,k in ((movies, 'Movies',0),(tv_shows, 'TV Shows',1)):\n",
        "    plt.subplot(1,2,k+1)\n",
        "    if i['date_added'].dtype != 'datetime64[ns]':\n",
        "        i['date_added'] = pd.to_datetime(i['date_added'])\n",
        "    i['month'] = i['date_added'].dt.month\n",
        "    df_month = i.groupby(['month']).agg({'title':'nunique'}).reset_index().sort_values(by=['month'],ascending=False)\n",
        "    plots= sns.barplot(x = 'month',y='title', data = df_month, palette='husl')\n",
        "    plt.title(f'{j} added added to Netflix by month')\n",
        "    plt.ylabel(f\"Number of {j} added on Netflix\")\n",
        "    plt.grid(linestyle='--', linewidth=0.3)\n",
        "    for bar in plots.patches:\n",
        "        plots.annotate(bar.get_height(),\n",
        "                    (bar.get_x() + bar.get_width() / 2,\n",
        "                     bar.get_height()), ha='center', va='center',\n",
        "                    size=12, xytext=(0, 8),\n",
        "                    textcoords='offset points')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7zOi6UKCNe8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing data for heatmap\n",
        "df['count'] = 1\n",
        "data = df.groupby('country')[['country','count']].sum().sort_values(by='count',ascending=False).reset_index()[:10]\n",
        "data = data['country']\n",
        "df_heatmap = df.loc[df['country'].isin(data)]\n",
        "df_heatmap = pd.crosstab(df_heatmap['country'],df_heatmap['rating'],normalize = \"index\").T\n",
        "\n",
        "# Plotting the heatmap\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
        "\n",
        "# Defining order of representation\n",
        "country_order = ['United States','India','United Kingdom','Canada','France','Japan','Spain','South Korea', 'Mexico']\n",
        "rating_order = ['Adult Content', 'Teen Content', 'Children Content', 'Family-friendly Content', 'Not Rated']\n",
        "\n",
        "# calling and plotting heatmap\n",
        "sns.heatmap(df_heatmap.loc[rating_order,country_order], cmap='Set2', square=True,linewidth=2.5,cbar=False,annot=True,fmt='1.0%',vmax=.6,vmin=0.05,ax=ax,annot_kws={\"fontsize\":12})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the relation between variables."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the US and UK are closely aligned with their Netflix target ages, but radically different from, example, India or Japan!\n",
        "\n",
        "Also, Mexico and Spain have similar content on Netflix for different age groups."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Hypothetical Statement 1:*\n",
        "* **Null Hypothesis**: The proportion of TV shows added on Netflix that are produced in the United States is not significantly different from the proportion of movies added on Netflix that are produced in the United States.\n",
        "\n",
        "* **Alternative Hypothesis**: The proportion of TV shows added on Netflix that are produced in the United States is significantly different from the proportion of movies added on Netflix that are produced in the United States.\n",
        "\n",
        "*Hypothetical Statement 2:*\n",
        "* **Null hypothesis**: There is no significant association between the type of content (movie or TV show) and the content rating on Netflix.\n",
        "\n",
        "**Alternative hypothesis**: There is a significant association between the type of content (movie or TV show) and the content rating on Netflix.\n",
        "\n",
        "*Hypothetical Statement 3:*\n",
        "* **Null hypothesis**: The number of movies and TV shows on Netflix is not significantly different.\n",
        "\n",
        "**Alternative hypothesis**: The number of movies on Netflix is significantly greater than the number of TV shows."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Hypothetical Statement 1:*\n",
        "* **Null Hypothesis**: The proportion of TV shows added on Netflix that are produced in the United States is not significantly different from the proportion of movies added on Netflix that are produced in the United States.\n",
        "\n",
        "* **Alternative Hypothesis**: The proportion of TV shows added on Netflix that are produced in the United States is significantly different from the proportion of movies added on Netflix that are produced in the United States."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from statsmodels.stats.proportion import proportions_ztest  #------> This function is used to perform z test of proportion.\n",
        "\n",
        "# Calculate the proportion of drama and comedy movies\n",
        "tv_proportion = np.sum(tv_shows['country'].str.contains('United States')) / len(tv_shows)\n",
        "movie_proportion = np.sum(movies['country'].str.contains('United States')) / len(movies)\n",
        "\n",
        "# Set up the parameters for the z-test\n",
        "count = [int(tv_proportion * len(tv_shows)), int(movie_proportion * len(movies))]\n",
        "nobs = [len(tv_shows), len(movies)]\n",
        "alternative = 'two-sided'\n",
        "\n",
        "# Perform the z-test\n",
        "z_stat, p_value = proportions_ztest(count=count, nobs=nobs, alternative=alternative)\n",
        "print('z-statistic: ', z_stat)\n",
        "print('p-value: ', p_value)\n",
        "\n",
        "# Set the significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Print the results of the z-test\n",
        "if p_value < alpha:\n",
        "    print(f\"Reject the null hypothesis.\")\n",
        "else:\n",
        "    print(f\"Fail to reject the null hypothesis.\")\n"
      ],
      "metadata": {
        "id": "toaPNNOxUQ2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " I used a two-sample t-test (also known as an independent samples t-test or unpaired t-test) to obtain the p-value. Specifically, I used the ttest_ind function from the scipy.stats module to perform the t-test. This test is appropriate for comparing the means of two independent samples, which is what we're doing here by comparing the number of movies on Netflix in the United States and India.\n",
        "\n",
        "It's worth noting that I assumed that the variances of the two populations are not equal (i.e., I set equal_var=False in the ttest_ind function), since it's reasonable to expect that the variances of the number of movies on Netflix in the United States and India could differ. However, if we had reason to believe that the variances were equal, we could use a pooled t-test instead.."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the two-sample t-test because it's appropriate for comparing the means of two independent samples, which is exactly what we're doing here. We have two independent samples of movies on Netflix in the United States and India, and we want to test whether the mean number of movies in the United States is significantly different from the mean number of movies in India.\n",
        "\n",
        "The t-test is also appropriate because the population standard deviations are unknown, and we're working with relatively small sample sizes (compared to the total number of movies on Netflix), so we need to use the sample standard deviations to estimate the population standard deviations.\n",
        "\n",
        "Additionally, the t-test assumes that the data are normally distributed (or approximately normally distributed), which is a reasonable assumption for this type of data.\n",
        "\n",
        "Overall, the two-sample t-test is a widely used and reliable statistical test for comparing the means of two independent samples, making it a good choice for this analysis.."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - According to the countplot, it appears that Netflix adds the highest number of movies and TV shows during the period between October and January. This period seems to be the busiest time of year for Netflix in terms of adding new content to its platform."
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Null hypothesis**: There is no significant association between the type of content (movie or TV show) and the content rating on Netflix.\n",
        "\n",
        "**Alternative hypothesis**: There is a significant association between the type of content (movie or TV show) and the content rating on Netflix."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "contingency_table = pd.crosstab(df['type'], df['rating'])\n",
        "\n",
        "chi2, pval, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "print('p-value:', pval)\n",
        "\n",
        "# Set the significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Print the results of the z-test\n",
        "if p_value < alpha:\n",
        "    print(f\"Reject the null hypothesis.\")\n",
        "else:\n",
        "    print(f\"Fail to reject the null hypothesis.\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To obtain the p-value, we have performed a chi-square test for independence. The chi-square test is used to determine if there is a significant association between two categorical variables. In this case, we wanted to test if there was a significant association between the time of year and the number of new movies and TV shows added to Netflix. The test involves comparing the observed frequencies of the contingency table (which shows the distribution of the data) to the expected frequencies under the assumption of independence. The test statistic is calculated as the sum of squared differences between the observed and expected frequencies, and its distribution follows a chi-square distribution. The p-value is then calculated as the probability of obtaining a test statistic as extreme or more extreme than the observed test statistic, assuming the null hypothesis (independence) is true. If the p-value is less than the significance level (usually 0.05), we reject the null hypothesis and conclude that there is a significant association between the two variables.."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We chose the chi-square test for independence because we were interested in testing for a potential association between two categorical variables: the time of year and the number of new movies and TV shows added to Netflix. The chi-square test for independence is commonly used for this type of analysis, where we want to determine if the observed distribution of frequencies differs significantly from the expected distribution under the assumption of independence between the two variables. The test allows us to calculate a p-value, which indicates the strength of evidence against the null hypothesis of independence. If the p-value is less than the significance level (usually 0.05), we reject the null hypothesis and conclude that there is a significant association between the two variables. Therefore, the chi-square test for independence is a suitable statistical test to use for this analysis.."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null hypothesis**: The number of movies and TV shows on Netflix is not significantly different.\n",
        "\n",
        "**Alternative hypothesis**: The number of movies on Netflix is significantly greater than the number of TV shows."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "# Count the number of movies and TV shows\n",
        "n_movies = df[df['type'] == 'Movie'].count()['type']\n",
        "n_tv_shows = df[df['type'] == 'TV Show'].count()['type']\n",
        "\n",
        "# Set the counts and sample sizes for the z-test\n",
        "counts = [n_movies, n_tv_shows]\n",
        "nobs = [len(df), len(df)]\n",
        "\n",
        "# Perform the z-test assuming equal proportions\n",
        "z_stat, p_val = proportions_ztest(counts, nobs, value=0, alternative='larger')\n",
        "\n",
        "# Print the results\n",
        "print('Number of movies:', n_movies)\n",
        "print('Number of TV shows:', n_tv_shows)\n",
        "print('z-statistic:', z_stat)\n",
        "print('p-value:', p_val)"
      ],
      "metadata": {
        "id": "aMZEp0BwKBBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used a two-sample z-test for proportions to obtain the p-value. The null hypothesis for the test is that the proportion of movies and TV shows on Netflix is equal, while the alternative hypothesis is that the proportion of movies is greater than the proportion of TV shows. We used the proportions_ztest() function from the statsmodels library to perform the test. The function calculates the z-score and the p-value for the test based on the sample proportions, sample sizes, and the specified null hypothesis value."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the two-sample z-test for proportions to compare the number of movies and TV shows on Netflix because the data consists of two categorical variables (movie or TV show), and we want to test if there is a significant difference between the proportions of these categories in the population. The two-sample z-test for proportions is an appropriate test to use when we have two independent samples, and we want to compare the proportion of successes in each sample. In this case, a success refers to a movie or TV show. The test assumes that the samples are large enough to apply the normal approximation to the binomial distribution. Since we have a large sample size in this case, we can use the z-test for proportions to test the hypothesis of interest.."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning**"
      ],
      "metadata": {
        "id": "Ph0afZWIbS--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Data %\n",
        "round(df.isna().sum()/len(df)*100, 2).sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "nk1k37s7nDk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing the continous value feature in a separate list\n",
        "continous_value_feature= [\"release_year\",\"day\",\"month\",\"year\"]\n",
        "\n",
        "# checking outliers with the help of box plot for continous features\n",
        "plt.figure(figsize=(16,5))\n",
        "for n,column in enumerate(continous_value_feature):\n",
        "  plt.subplot(1, 5, n+1)\n",
        "  sns.boxplot(df[column])\n",
        "  plt.title(f'{column.title()}',weight='bold')\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "PlEsBK2TAOrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although we have some of the anomalies in continous feature but we will not treat by considering outliers as some of the Movies/TV Shows has released or added early on Netflix.\n",
        "\n",
        "1.Except for the release year, almost all of the data are presented in text format.\n",
        "\n",
        "2.The textual format contains the data we need to build a cluster/building model. Therefore, there is no need to handle outliers."
      ],
      "metadata": {
        "id": "5G5dfB67BBbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for null values after treating them.\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "HAXKDlXinp26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.Textual Data Preprocessing**"
      ],
      "metadata": {
        "id": "0fM9C1OrdscP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is textual data preprocessing?**\n",
        "\n",
        "Textual data preprocessing is the process of preparing text data for analysis or modeling. It includes a series of steps that are applied to raw text data in order to clean, organize and standardize it so that it can be easily analyzed or used as input for natural language processing or machine learning models. The preprocessing steps typically include tokenization, stop-word removal, stemming or lemmatization, lowercasing, removing punctuation, and removing numbers. The goal of textual data preprocessing is to prepare the data for further analysis and modeling by removing irrelevant information and standardizing the format of the text. This can help improve the accuracy and effectiveness of the analysis or modeling."
      ],
      "metadata": {
        "id": "wc2EOy3Fd5N-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modeling Approch**\n",
        "\n",
        "Imagine you're organizing a cluttered closet - you want to group items that have similar attributes to make them easier to find. Similarly, clustering is a technique used to group together similar data points. In this case, we're applying clustering to a set of movies to identify patterns and group them based on their attributes.\n",
        "\n",
        "Before clustering, we need to prepare the textual data. Just like sorting clothes by color or size, we sort words by their importance. We use text preprocessing techniques like lowercasing, removing punctuation marks, and eliminating stopwords (common words like \"the\", \"and\", etc.) that don't add much meaning. Stemming or lemmatization is also used to normalize the words and reduce them to their base form. Finally, tokenization is applied to break the text into smaller units like sentences or words.\n",
        "\n",
        "Now that we've tidied up the data, we can start clustering. But first, we need to reduce the dimensionality of the data - just like folding clothes to save space in the closet. Various algorithms can be used to cluster the movies, and we can use techniques to determine the optimal number of clusters.\n",
        "\n",
        "Once we've built the optimal number of clusters, we can explore their contents using wordclouds. Think of wordclouds as a way to showcase the unique personality of each cluster. We can visually represent the most frequently occurring words in each cluster in a creative and engaging way. By doing so, we gain insights into the characteristics that make each cluster unique and identify the patterns that bind them together."
      ],
      "metadata": {
        "id": "7k_wc0IYek8A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "m9vMGkCdey3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction\n",
        "df['rating'] = df['rating'].astype(str)\n",
        "# Concatenate columns into a single column 'tags'\n",
        "df['content_detail'] = df['description'] + df['listed_in'] + df['cast'] + df['country'] + df['director'] + df['rating']\n",
        "\n",
        "#checking the manipulation\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "wQ5vIyLqinM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.content_detail[0]"
      ],
      "metadata": {
        "id": "8VTgk1VXiqzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "EQ9vzJioF1p6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "df['content_detail']= df['content_detail'].str.lower()\n"
      ],
      "metadata": {
        "id": "eKErH9eRF1Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "_Eb9jQW6GWqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to remove punctuations\n",
        "def remove_punctuations(text):\n",
        "    '''This function is used to remove the punctuations from the given sentence'''\n",
        "    #imorting needed library\n",
        "    import string\n",
        "    # replacing the punctuations with no space, which in effect deletes the punctuation marks.\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    # return the text stripped off punctuation marks\n",
        "    return text.translate(translator)"
      ],
      "metadata": {
        "id": "dwNe9KzuGhZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing Punctuations from the content_detail\n",
        "df['content_detail']= df['content_detail'].apply(remove_punctuations)"
      ],
      "metadata": {
        "id": "gIjDMVZXIq9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "ZHHfGE07I1XH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_url_and_numbers(text):\n",
        "    '''This function is used to remove the URL's and Numbers from the given sentence'''\n",
        "    # importing needed libraries\n",
        "    import re\n",
        "    import string\n",
        "\n",
        "    # Replacing the URL's with no space\n",
        "    url_number_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    text= re.sub(url_number_pattern,'', text)\n",
        "\n",
        "    # Replacing the digits with one space\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "\n",
        "    # return the text stripped off URL's and Numbers\n",
        "    return text"
      ],
      "metadata": {
        "id": "XlB5wZRtI9jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "df['content_detail']= df['content_detail'].apply(remove_url_and_numbers)"
      ],
      "metadata": {
        "id": "94Vhh0a4JEt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "hNwOfDTyJNNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a set of English stop words\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# displaying stopwords\n",
        "print(stop_words)"
      ],
      "metadata": {
        "id": "UWfnnowWJOy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "def remove_stopwords_and_whitespaces(text):\n",
        "    '''This function is used for removing the stopwords from the given sentence'''\n",
        "    text = [word for word in text.split() if not word in stopwords.words('english')]\n",
        "\n",
        "    # joining the list of words with space separator\n",
        "    text=  \" \".join(text)\n",
        "    \n",
        "    # removing whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    # return the manipulated string\n",
        "    return text"
      ],
      "metadata": {
        "id": "3snuyDxFJZU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "df['content_detail']= df['content_detail'].apply(remove_stopwords_and_whitespaces)\n"
      ],
      "metadata": {
        "id": "3bQniKmoJgl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Tokenization"
      ],
      "metadata": {
        "id": "RblPtbK-KeTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading needed libraries\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Tokenization\n",
        "df['content_detail']= df['content_detail'].apply(nltk.word_tokenize)"
      ],
      "metadata": {
        "id": "Ip7KU91OP4N1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Text Normalization"
      ],
      "metadata": {
        "id": "nHSY3UfrQPlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "# Importing WordNetLemmatizer from nltk module\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Creating instance for wordnet\n",
        "wordnet  = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "DnYicAXJQQq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatizing_sentence(text):\n",
        "    '''This function is used for lemmatizing (changing the given word into meaningfull word) the words from the given sentence'''\n",
        "    text = [wordnet.lemmatize(word) for word in text]\n",
        "\n",
        "    # joining the list of words with space separator\n",
        "    text=  \" \".join(text)\n",
        "\n",
        "    # return the manipulated string\n",
        "    return text"
      ],
      "metadata": {
        "id": "I6Ck8LAYQXAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading needed libraries\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Rephrasing text by applying defined lemmatizing function\n",
        "df['content_detail']= df['content_detail'].apply(lemmatizing_sentence)\n"
      ],
      "metadata": {
        "id": "ncPVdukoQc5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Part of speech tagging"
      ],
      "metadata": {
        "id": "cWwCO8eKQ0Gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the text into words before POS Taging\n",
        "df['conten_detail'] = df['content_detail'].apply(nltk.word_tokenize).apply(nltk.pos_tag)\n",
        "\n",
        "# Checking the observation after manipulation\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "YEJHGAMNQzqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Removing Stopwords and Lower Casing.\n",
        "Removing stop words and lowercasing words are common pre-processing steps in natural language processing (NLP) tasks.\n",
        "\n",
        "Stop words are words that are commonly used in a language but do not convey much meaning on their own, such as \"a,\" \"an,\" \"the,\" and \"is.\" These words can add noise to the data and can sometimes affect the performance of NLP models, so they are often removed as a pre-processing step.\n",
        "\n",
        "Lowercasing words is the process of converting all the words in a text to lowercase. This is a common pre-processing step in NLP tasks, as it can be useful for a few reasons:\n",
        "\n",
        "Case differences can be ignored: By lowercasing the words, you can treat words with different capitalization as the same word, which can be useful in tasks such as information retrieval or text classification where case differences are not important.\n",
        "Vocabulary size is reduced: Lowercasing the words can also reduce the size of the vocabulary, which can make it easier to work with larger texts or texts in languages with a high number of inflected forms."
      ],
      "metadata": {
        "id": "eAiTaTjLpYbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Text Vectorization"
      ],
      "metadata": {
        "id": "VWF3pACTRMCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the object of tfid vectorizer\n",
        "tfidf = TfidfVectorizer(stop_words='english', lowercase=False, max_features = 10000)   # max features = 10000 to prevent system from crashing\n",
        "\n",
        "# fit the vectorizer using the text data\n",
        "tfidf.fit(df['content_detail'])\n",
        "\n",
        "# collect the vocabulary items used in the vectorizer\n",
        "dictionary = tfidf.vocabulary_.items()"
      ],
      "metadata": {
        "id": "8wA3t0E-sN5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dictionary)) #number of independet features created from \"tags\" columns ---> max_features=10000"
      ],
      "metadata": {
        "id": "PTOnWvjKsuOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting on TfidfVectorizer\n",
        "x= tfidf.fit_transform(df['content_detail'])\n",
        "\n",
        "# Checking shape of the formed document matrix\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "_NlRNhZZszca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Word/Text vectorization is the process of representing words as numerical vectors. This is important in NLP tasks because most machine learning models expect numerical input and cannot work with raw text data directly. Word vectorization allows you to input the words into a machine learning model in a way that preserve the meaning and context of the words. Word vectorization can also be used to measure the similarity between words using vector arithmetic."
      ],
      "metadata": {
        "id": "9GhLsoKjsY3d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "IZh8ONV1s7aL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "cVGsSMZYR_z_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use PCA (Principal component Analysis) to reduce the dimensionality of data.\n",
        "\n",
        "Dimensionality reduction is the process of reducing the number of features or dimensions in a dataset while preserving as much information as possible. It is a common step in machine learning and data analysis, as high-dimensional datasets can be difficult to work with and can sometimes suffer from the curse of dimensionality."
      ],
      "metadata": {
        "id": "6j_XBgsctFqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensionality Reduction\n",
        "# Importing PCA from sklearn\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Defining PCA object with desired number of components\n",
        "pca = PCA()\n",
        "\n",
        "# Fitting the PCA model\n",
        "pca.fit(x.toarray())\n",
        "\n",
        "# percent of variance captured by each component\n",
        "variance = pca.explained_variance_ratio_\n",
        "print(f\"Explained variance: {variance}\")"
      ],
      "metadata": {
        "id": "Am_vYZyIXwRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ploting the percent of variance captured versus the number of components in order to determine the reduced dimensions\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(range(1, len(variance)+1), np.cumsum(pca.explained_variance_ratio_))\n",
        "ax.set_xlabel('Number of Components')\n",
        "ax.set_ylabel('Percent of Variance Captured')\n",
        "ax.set_title('PCA Analysis')\n",
        "plt.grid(linestyle='--', linewidth=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EuQFbGITtPoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We find that 100% of the variance is explained by about ~7770 components.\n",
        "\n",
        "Also, more than 80% of the variance is explained just by 3000 components.\n",
        "\n",
        "Hence to simplify the model, and reduce dimensionality, which will still be able to capture more than 95% of variance."
      ],
      "metadata": {
        "id": "0b5fSEMbuq1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Now we are passing the argument so that we can capture 95% of variance.\n",
        "# Defining instance\n",
        "pca_tuned = PCA(n_components=0.95)\n",
        "\n",
        "# Fitting and transforming the model\n",
        "pca_tuned.fit(x.toarray())\n",
        "x_transformed = pca_tuned.transform(x.toarray())\n",
        "\n",
        "# Checking the shape of transformed matrix\n",
        "x_transformed.shape"
      ],
      "metadata": {
        "id": "ZRhu-oeiu0LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why?"
      ],
      "metadata": {
        "id": "sBCHtz9ddXV4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used PCA (Principal Component Analysis) for dimensionality reduction. PCA is a widely used technique for reducing the dimensionality of high-dimensional data sets while retaining most of the information in the original data. \n",
        "\n",
        "PCA works by finding the principal components of the data, which are linear combinations of the original features that capture the maximum amount of variation in the data. By projecting the data onto these principal components, PCA can reduce the number of dimensions while retaining most of the information in the original data.\n",
        "\n",
        "PCA is a popular choice for dimensionality reduction because it is simple to implement, computationally efficient, and widely available in most data analysis software packages. Additionally, PCA has been extensively studied and has a strong theoretical foundation, making it a reliable and well-understood method."
      ],
      "metadata": {
        "id": "ymtBQsWSdZYO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Clusters implementation**"
      ],
      "metadata": {
        "id": "dpxl0BibvyXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.**K-Means Clustering**\n",
        "\n",
        "K-means clustering is a type of unsupervised machine learning algorithm used for partitioning a dataset into K clusters based on similarity of data points. The goal of the algorithm is to minimize the sum of squared distances between each data point and its corresponding cluster centroid. It works iteratively by assigning each data point to its nearest centroid and then re-computing the centroid of each cluster based on the new assignments. The algorithm terminates when the cluster assignments no longer change or when a maximum number of iterations is reached.\n",
        "\n",
        "Let's just itterate over a loop of 1 to 16 clusters and try to find the optimal number of clusters with ELBOW method."
      ],
      "metadata": {
        "id": "KcNmMSCXv8g3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Determining optimal value of K using KElbowVisualizer\n",
        "# Importing needed library\n",
        "from sklearn.cluster import KMeans\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "# Instantiate the clustering model and visualizer\n",
        "model = KMeans(random_state=0)\n",
        "visualizer = KElbowVisualizer(model, k=(1,16),locate_elbow=False)\n",
        "\n",
        "#Fit the data to the visualizer\n",
        "visualizer.fit(x_transformed)\n",
        "\n",
        "# Finalize and render the figure\n",
        "visualizer.show() "
      ],
      "metadata": {
        "id": "ZUy4ysOVv7hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here it seems that the elbow is forming at the 2 clusters but before blindly believing it let's plot one more chart that itterates over the same number of cluters and determines the Silhouette Score at every point.\n",
        "\n",
        "Okay, but what is **Silhouette Score**?\n",
        "\n",
        "The silhouette score is a measure of how similar an object is to its own cluster compared to other clusters. It is used to evaluate the quality of clustering, where a higher score indicates that objects are more similar to their own cluster and dissimilar to other clusters.\n",
        "\n",
        "The silhouette score ranges from -1 to 1, where a score of 1 indicates that the object is well-matched to its own cluster, and poorly-matched to neighboring clusters. Conversely, a score of -1 indicates that the object is poorly-matched to its own cluster, and well-matched to neighboring clusters."
      ],
      "metadata": {
        "id": "7MrKKmTIxIdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Determining optimal value of K using KElbowVisualizer\n",
        "# Importing needed library\n",
        "from sklearn.cluster import KMeans\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "# Instantiate the clustering model and visualizer\n",
        "visualizer = KElbowVisualizer(model, k=(2,16), metric='silhouette', timings=True, locate_elbow=False)\n",
        "\n",
        "# Fit the data to the visualizer\n",
        "visualizer.fit(x_transformed)\n",
        "\n",
        "# Finalize and render the figure\n",
        "visualizer.show()   "
      ],
      "metadata": {
        "id": "CXugGBP9xR5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Computing Silhouette score for each k\n",
        "# Importing needed libraries\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Defining Range\n",
        "k_range = range(2, 7)\n",
        "for k in k_range:\n",
        "    Kmodel = KMeans(n_clusters=k)\n",
        "    labels = Kmodel.fit_predict(x_transformed)\n",
        "    score = silhouette_score(x, labels)\n",
        "    print(\"k=%d, Silhouette score=%f\" % (k, score))"
      ],
      "metadata": {
        "id": "U0zwBOP4teOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above plots (Elbow plot and Sillhouette plot) it is very clear that the Silhoutte score is comparatively good for 4 number of clusters, so we will consider 4 cluster in kmeans analysis.\n",
        "\n",
        "Now let's plot and see how our data points look like after assigning to their respective clusters."
      ],
      "metadata": {
        "id": "2y2vPwTOnbE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#training the K-means model on a dataset  \n",
        "kmeans = KMeans(n_clusters=4, init='k-means++', random_state= 0)  \n",
        "\n",
        "#predict the labels of clusters.\n",
        "plt.figure(figsize=(10,6), dpi=120)\n",
        "label = kmeans.fit_predict(x_transformed)\n",
        "#Getting unique labels\n",
        "unique_labels = np.unique(label)\n",
        " \n",
        "#plotting the results:\n",
        "for i in unique_labels:\n",
        "    plt.scatter(x_transformed[label == i , 0] , x_transformed[label == i , 1] , label = i)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TXExeAyznkqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 4 different clusters but unfortunately the above plot is in TWO-DIMENSIONAL. Let's plot the above figure in 3D using mplot3d library and see if we are getting the separated clusters."
      ],
      "metadata": {
        "id": "N2KaripmntFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing library to visualize clusters in 3D\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Plot the clusters in 3D\n",
        "fig = plt.figure(figsize=(20,8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "colors = ['r', 'g', 'b', 'y']\n",
        "for i in range(len(colors)):\n",
        "    ax.scatter(x_transformed[kmeans.labels_ == i, 2], x_transformed[kmeans.labels_ == i, 0], x_transformed[kmeans.labels_ == i, 1], c=colors[i])\n",
        "\n",
        "# Rotate the plot 30 degrees around the X axis and 45 degrees around the Z axis\n",
        "ax.view_init(elev=20, azim=-120)\n",
        "ax.set_xlabel('x-axis')\n",
        "ax.set_ylabel('y-axis')\n",
        "ax.set_zlabel('z-axis')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NAX4BlMGxe25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cool, we can easily differentiate the all 4 clusters with nacked eye. Now let's assign the 'Conent' in their respective cluster by appending 1 more attribute in the final dataframe."
      ],
      "metadata": {
        "id": "kB77f_26nzss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add cluster values to the dateframe.\n",
        "df['kmeans_cluster'] = kmeans.labels_"
      ],
      "metadata": {
        "id": "Hkvnw_UAxzUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance ?"
      ],
      "metadata": {
        "id": "vOENUsVUrK75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Starting with defining a function that plot a wordcloud for each of the attribute in the given dataframe."
      ],
      "metadata": {
        "id": "i9gWt0rgrVKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kmeans_wordcloud(cluster_number, column_name):\n",
        "    '''function for Building a wordcloud for the movie/shows'''\n",
        "    \n",
        "    #Importing libraries\n",
        "    from wordcloud import WordCloud, STOPWORDS\n",
        "    \n",
        "    # Filter the data by the specified cluster number and column name\n",
        "    df_wordcloud = df_new[['kmeans_cluster', column_name]].dropna()\n",
        "    df_wordcloud = df_wordcloud[df_wordcloud['kmeans_cluster'] == cluster_number]\n",
        "    df_wordcloud = df_wordcloud[df_wordcloud[column_name].str.len() > 0] \n",
        "    \n",
        "    # Combine all text documents into a single string\n",
        "    text = \" \".join(word for word in df_wordcloud[column_name])\n",
        "    \n",
        "    # Create the word cloud\n",
        "    wordcloud = WordCloud(stopwords=set(STOPWORDS), background_color=\"black\").generate(text)\n",
        "    \n",
        "    # Convert the wordcloud to a numpy array\n",
        "    image_array = wordcloud.to_array()\n",
        "    \n",
        "    # Return the numpy array\n",
        "    return image_array"
      ],
      "metadata": {
        "id": "b1ytKf3Ex6rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing the above defined function and plotting the wordcloud of each attribute\n",
        "fig, axs = plt.subplots(nrows=4, ncols=4, figsize=(20, 15))\n",
        "for i in range(4):\n",
        "    for j, col in enumerate(['description', 'listed_in', 'country', 'title']):\n",
        "        axs[j][i].imshow(kmeans_wordcloud(i, col))\n",
        "        axs[j][i].axis('off')\n",
        "        axs[j][i].set_title(f'Cluster {i}, {col}',fontsize=14, fontweight='bold')    \n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DN3urIVwyGnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of movies and tv shows in each cluster\n",
        "plt.figure(figsize=(8,5))\n",
        "graph = sns.countplot(x='kmeans_cluster',data=df, hue='type')\n",
        "plt.title('Number of movies and TV shows in each cluster - Kmeans Clustering')\n",
        "\n",
        "# adding value count on the top of bar\n",
        "for p in graph.patches:\n",
        "   graph.annotate(format(p.get_height(), '.0f'), (p.get_x(), p.get_height()))"
      ],
      "metadata": {
        "id": "c8fKY6i1yP6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Successfully built 5 clusters using the k-means clustering algorithm."
      ],
      "metadata": {
        "id": "dxh65kOtyWEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building wordclouds for different clusters in K-Means Clustering**"
      ],
      "metadata": {
        "id": "R94thfg1yXiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kmeans_worldcloud(cluster_number, column_name):\n",
        "  \n",
        "  '''function for Building a wordcloud for the movie/shows'''\n",
        "\n",
        "  df_wordcloud = df[['kmeans_cluster',column_name]].dropna()\n",
        "  df_wordcloud = df_wordcloud[df_wordcloud['kmeans_cluster']==cluster_number]\n",
        "  \n",
        "  # text documents\n",
        "  text = \" \".join(word for word in df_wordcloud[column_name])\n",
        "\n",
        "  # create the word cloud\n",
        "  wordcloud = WordCloud(stopwords=set(STOPWORDS), background_color=\"white\").generate(text)\n",
        "  \n",
        "  # Generate a word cloud image\n",
        "  plt.imshow(wordcloud, interpolation='bilinear')\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "77xvjoWAyf2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word Cloud on \"description\" column for different cluster**"
      ],
      "metadata": {
        "id": "Vl9gsYziyofr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'description')"
      ],
      "metadata": {
        "id": "gvI7ElpSyrez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'cast')"
      ],
      "metadata": {
        "id": "BdCZXIm7y5MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'director')"
      ],
      "metadata": {
        "id": "vRu3Sli8y-Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'listed_in')"
      ],
      "metadata": {
        "id": "aZVhslx7zCI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'country')"
      ],
      "metadata": {
        "id": "Eov5R1yVzHS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'title')"
      ],
      "metadata": {
        "id": "9l_dZ6yRzLwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2.Hierarchical clustering**"
      ],
      "metadata": {
        "id": "dtbZkRTQzqrp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After applying the agglomerative hierarchical clustering algorithm, the resulting clusters are displayed in a dendrogram, which is a tree-like structure. The dendrogram shows the relationships between the clusters at each level of the hierarchy.\n",
        "\n",
        "To determine the optimal number of clusters for our data, we can visually inspect the dendrogram and look for the largest vertical distance that does not intersect any horizontal line. This distance represents the largest distance between any two merged clusters, and thus the point at which the clusters are most dissimilar.\n",
        "\n",
        "We can then draw a horizontal line at this distance and count the number of vertical lines it intersects. This number corresponds to the optimal number of clusters for our data."
      ],
      "metadata": {
        "id": "ZbYI0Bl_0Jxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a dendogram to decide the number of clusters\n",
        "plt.figure(figsize=(10, 7))  \n",
        "dend = shc.dendrogram(shc.linkage(X, method='ward'))\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Netflix Shows')\n",
        "plt.ylabel('Distance')\n",
        "plt.axhline(y= 4, color='r', linestyle='--')\n",
        "     "
      ],
      "metadata": {
        "id": "BULYx8GizxRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**At a distance of 4 units, 7 clusters can be built using the agglomerative clustering algorithm.**"
      ],
      "metadata": {
        "id": "VduutNQN0V7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building 7 clusters using the Agglomerative clustering algorithm:"
      ],
      "metadata": {
        "id": "kIue8a9t0bj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting hierarchical clustering model\n",
        "hierarchical = AgglomerativeClustering(n_clusters=7, affinity='euclidean', linkage='ward')  \n",
        "hierarchical.fit_predict(X)\n",
        "     "
      ],
      "metadata": {
        "id": "PNR3b1xR0em1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a hierarchical cluster number attribute\n",
        "df['hierarchical_cluster'] = hierarchical.labels_\n",
        "     "
      ],
      "metadata": {
        "id": "Ib0OrV6b0i_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)[['type', 'title', 'director', 'cast', 'country', 'rating', 'listed_in', 'description', 'hierarchical_cluster']]"
      ],
      "metadata": {
        "id": "82YtODU60kMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of movies and tv shows in each cluster\n",
        "plt.figure(figsize=(10,5))\n",
        "graph = sns.countplot(x='hierarchical_cluster',data=df, hue='type')\n",
        "plt.title('Number of movies and tv shows in each cluster - Hierarchical Clustering')\n",
        "\n",
        "# adding value count on the top of bar\n",
        "for p in graph.patches:\n",
        "   graph.annotate(format(p.get_height(), '.0f'), (p.get_x(), p.get_height()))"
      ],
      "metadata": {
        "id": "MzHPIssd0n_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Successfully built 7 clusters using the Agglomerative (hierarchical) clustering algorithm."
      ],
      "metadata": {
        "id": "X9Tr38nu0vUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building wordclouds for different clusters in hierarchical Clustering**"
      ],
      "metadata": {
        "id": "-Q9KUL8E03ED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hierarchical_worldcloud(cluster_number, column_name):\n",
        "  \n",
        "  '''function for Building a wordcloud for the movie/shows'''\n",
        "\n",
        "  df_wordcloud = df[['hierarchical_cluster',column_name]].dropna()\n",
        "  df_wordcloud = df_wordcloud[df_wordcloud['hierarchical_cluster']==cluster_number]\n",
        "  \n",
        "  # text documents\n",
        "  text = \" \".join(word for word in df_wordcloud[column_name])\n",
        "\n",
        "  # create the word cloud\n",
        "  wordcloud = WordCloud(stopwords=set(STOPWORDS), background_color=\"white\").generate(text)\n",
        "  \n",
        "  # Generate a word cloud image\n",
        "  plt.imshow(wordcloud, interpolation='bilinear')\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "fKGSx0-h09Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word Cloud on \"title\" column for different cluster**"
      ],
      "metadata": {
        "id": "FNT4oLfo1Biy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(7):\n",
        "  print(f'cluster {i}')\n",
        "  hierarchical_worldcloud(i,'title')"
      ],
      "metadata": {
        "id": "092hG3Qk1II2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word Cloud on \"description\" column for different cluster**"
      ],
      "metadata": {
        "id": "J1IUaxl31NT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(7):\n",
        "  print(f'cluster {i}')\n",
        "  hierarchical_worldcloud(i,'description')"
      ],
      "metadata": {
        "id": "h121gdhy1Qwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word Cloud on \"cast\" column for different cluster**"
      ],
      "metadata": {
        "id": "SnKQiFGR1XzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(7):\n",
        "  print(f'cluster {i}')\n",
        "  hierarchical_worldcloud(i,'cast')"
      ],
      "metadata": {
        "id": "j3bDi3vK12LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word Cloud on \"country\" column for different cluster**"
      ],
      "metadata": {
        "id": "rNVk8aug16E_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(7):\n",
        "  print(f'cluster {i}')\n",
        "  hierarchical_worldcloud(i,'country')"
      ],
      "metadata": {
        "id": "UD-Pv2b919Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word Cloud on \"listed_in (genre)\" column for different cluster**"
      ],
      "metadata": {
        "id": "Uvp1friM2Ku1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(7):\n",
        "  print(f'cluster {i}')\n",
        "  hierarchical_worldcloud(i,'listed_in')"
      ],
      "metadata": {
        "id": "RjNv4SRf2R-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Content Based Recommendation System**\n",
        "\n",
        "Content-based recommendation systems recommend items to a user by using the similarity of items. This recommender system recommends products or items based on their description or features. It identifies the similarity between the products based on their descriptions.\n",
        "\n",
        "It short notes which items a particular user likes and also the items that the users with behavior and likings like him/her likes, to recommend items to that user.\n",
        "\n",
        "We can build a simple content based recommender system based on the similarity of the movie/shows.\n",
        "If a person has watched a show on Netflix, the recommender system must be able to recommend a list of similar shows that s/he likes.\n",
        "To get the similarity score of the shows, we can use cosine similarity.\n",
        "The similarity between two vectors (A and B) is calculated by taking the dot product of the two vectors and dividing it by the magnitude value. We can simply say that the cosine similarity score of two vectors increases as the angle between them decreases."
      ],
      "metadata": {
        "id": "KXBBpNtx2WS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# veryfying index\n",
        "df[['show_id', 'title', 'tags']]"
      ],
      "metadata": {
        "id": "RRznAHNz2fcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.The dataframe under consideration has a total of 7770 rows. However, due to the removal of some rows containing null values, the last index shown in the dataframe is 7786.\n",
        "\n",
        "2.To build a content-based recommendation system, we calculate the similarity score based on a specific index_id with respect to the corresponding \"tags\" column.\n",
        "\n",
        "3.Failure to reset the index may result in the calculation of cosine similarity for a different index, leading to incorrect recommendations. Hence, resetting the index is essential to ensure that the recommendations are based on the correct index.\n",
        "\n",
        "4.Resetting the index involves assigning a new sequential index to each row of the dataframe, starting from 0. This ensures that each row has a unique and identifiable index, making it easier to perform computations and obtain accurate results.\n",
        "\n",
        "5.Therefore, resetting the index is a crucial step in building a content-based recommendation system, as it ensures that the recommendations are based on the correct index and leads to more accurate and relevant recommendations."
      ],
      "metadata": {
        "id": "cvlFZu-Z2zes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining new dataframe for building recommandation system\n",
        "recommender_df = df.copy()\n",
        "\n",
        "# reseting index\n",
        "recommender_df.reset_index(inplace=True)\n",
        "\n",
        "# checking whether or not reset index properly \n",
        "recommender_df[['show_id', 'title', 'tags']]"
      ],
      "metadata": {
        "id": "q6_cFUZI3Bi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see above dataframe We successfully reset the index. Now dataset is ready to build content based recommandation system"
      ],
      "metadata": {
        "id": "kfBjiAcY3Jz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping show-id and index column\n",
        "recommender_df.drop(columns=['index', 'show_id'], inplace=True)"
      ],
      "metadata": {
        "id": "lbPVM7DN3K40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"before reset index id for movie 'Zero' : {df[df['title'] == 'Zero'].index[0]}\")  # index[0] --> to locate index position\n",
        "print(f\"after reset index id for movie 'Zero': {recommender_df[recommender_df['title'] == 'Zero'].index[0]}\")"
      ],
      "metadata": {
        "id": "GdJqrM7l3TYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calling out transformed array independent features created from tags(cluster) column after performing PCA for dimenssionality reduction.\n",
        "X"
      ],
      "metadata": {
        "id": "86Moux-e3YIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate cosine similarity\n",
        "similarity = cosine_similarity(X)\n",
        "similarity"
      ],
      "metadata": {
        "id": "Dr8HHqfZ3hNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function for list down top 10 recommended movie on the basis of cosine similarity score.**"
      ],
      "metadata": {
        "id": "FgK0gsur3obi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend(movie):\n",
        "    '''\n",
        "    This function list down top ten movies on the basis of similarity score for that perticular movie.\n",
        "    '''\n",
        "    print(f\"If you liked '{movie}', you may also enjoy: \\n\")\n",
        "\n",
        "    # find out index position\n",
        "    index = recommender_df[recommender_df['title'] == movie].index[0]\n",
        "\n",
        "    # sorting on the basis of simliarity score, In order to find out distaces from recommended one\n",
        "    distances = sorted(list(enumerate(similarity[index])), reverse=True, key=lambda x:x[1])\n",
        "    \n",
        "    # listing top ten recommenaded movie\n",
        "    for i in distances[1:11]:\n",
        "        print(df.iloc[i[0]].title)"
      ],
      "metadata": {
        "id": "hAd89u2b3wEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend('Naruto')"
      ],
      "metadata": {
        "id": "fjmLfVs04LK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend('Our Planet')"
      ],
      "metadata": {
        "id": "UHS1JxN84ToJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend('Phir Hera Pheri')"
      ],
      "metadata": {
        "id": "MxD1ZX-34YZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Welcome to our exciting journey of exploring the world of Netflix shows! Our goal was to cluster the shows into groups based on their similarities and differences, ultimately creating a content-based recommender system that suggests 10 shows based on the user's viewing history.\n",
        "\n",
        "With over 7787 records and 11 attributes, we began our adventure by delving into the dataset's missing values and performing exploratory data analysis (EDA). Our findings revealed that Netflix boasts more movies than TV shows, with a rapidly growing collection of shows from the United States.\n",
        "\n",
        "To cluster the shows, we focused on six key attributes: director, cast, country, genre, rating, and description. We transformed these attributes into a 10000-feature TFIDF vectorization, then used Principal Component Analysis (PCA) to tackle the curse of dimensionality. By reducing the components to 3000, we were able to capture more than 80% of the variance.\n",
        "\n",
        "Next, we used two clustering algorithms, K-Means and Agglomerative clustering, to group the shows. K-Means determined that the optimal number of clusters was 5, as confirmed by the elbow method and Silhouette score analysis. Meanwhile, Agglomerative clustering suggested 7 clusters, which we visualized using a dendrogram.\n",
        "\n",
        "But we didn't stop there. We then created a content-based recommender system using the similarity matrix obtained through cosine similarity. This system provides personalized recommendations based on the type of show the user has watched, giving them 10 top-notch suggestions to explore.\n",
        "\n",
        "Join us in discovering the diverse world of Netflix shows, and let our recommender system guide you to your next binge-worthy obsession."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}